\documentclass{article}

\usepackage{amsmath,amsthm,amsfonts,amssymb,amscd}
\usepackage{booktabs} % for better table formatting
\usepackage{siunitx} % for aligning table columns by decimal point
\usepackage{graphicx}
\usepackage{hyperref}

\begin{document}

\title{\vspace{-3cm}VAE Problem Set}
\author{Group U8: Lake Yin, Zhiqi Wang}
\date{\today}
\maketitle



\section*{Problem 1}

Here's the code implementation of VAE in PyTorch. (\href{https://github.com/ZhiqiEliWang/csci4968-VAE-project}{https://github.com/ZhiqiEliWang/csci4968-VAE-project}). In assignment 4, we have done an reconstruction of Fashion-MNIST dataset. In this problem, we will build a VAE on assignment 4 based on our implementation of VAE. Import the data and partition it into a test set and training set.


\subsection*{1. Encoder class}
Write a class \texttt{Encoder} that is a subclass of PyTorch \texttt{nn.module} that implements the encoder section of a VAE. To do this, the class should implement the following functions:
\subsubsection*{Constructor}
An encoder constructor \texttt{\_\_init\_\_(self, c1, c2, lat, k)}, where \texttt{c1} is the output channel size of the first convolution layer, \texttt{c2} is the output channel size of the second convolution layer, \texttt{lat} is the latent dimension size, and \texttt{k} is the kern3l size. Do not forget \texttt{super(Encoder, self).\_\_init\_\_()}. The constructor initialize two convolution layers with \texttt{Conv2d}, as well as two linear layers, \texttt{mean} and \texttt{std}. These two linear layers should both be the same size and accept a flattened version of the final output from the convolution layers. The linear layer size can be determined with the formula 

\[c(d - (k - 1)) ^ 2\]

where $c$ is the number of output channels for the last layer, $d$ is the height or width of the image input, and $k$ is the kernel size. We recommend a kernel size of 3 and output channel sizes of 16 and 32 for the first and second convolution layers, respectively.

\subsubsection*{Forward function}
A function \texttt{forward(self, x)}, where \texttt{x} is a batch of images. The function should apply the convolution layers to \texttt{x} in order with ReLu activation, then flatten the output into one dimension. Then, the function should calculate \texttt{mu} using the \texttt{mean} linear layer on the flattened output and calculate \texttt{sigma} by applying the exponential function to output of passing flatten output through the \texttt{std} layer. The function should return \texttt{mu} and \texttt{sigma} as a tuple. 

\subsection*{2. Decoder class}
Write a class \texttt{Decoder} that is a subclass of PyTorch \texttt{nn.module} that implements the decoder section of a VAE. To do this, the class should implement the following functions:
\subsubsection*{Constructor}
An encoder constructor \texttt{\_\_init\_\_(self, c1, c2, lat, k)}, where \texttt{c1} is the output channel size of the first encoder convolution layer, \texttt{c2} is the output channel size of the second encoder convolution layer, \texttt{lat} is the latent dimension size, and \texttt{k} is the kernel size. Do not forget \texttt{super(Decoder, self).\_\_init\_\_()}. The constructor initialize a linear layer that matches the size of the \texttt{mean} or \texttt{std} encoder layers, and two transpose convolution layers with \texttt{ConvTranspose2d} with output channel sizes in reverse order to the encoder convolution layers. (So \texttt{c2} and \texttt{c1}, in that order.)

\subsubsection*{Forward function}
A function \texttt{forward(self, z)}, where \texttt{z} is a batch of latent vectors. The function should apply ReLu to \texttt{z}, then unflatten \texttt{z} into a batch of images with size \texttt{(b, c2, d, d)} where \texttt{b} is the batch size. Then, the function should apply the transpose convolution layers and return the output. The first transpose convolution layer should have ReLu activation and the second layer should have sigmoid activation.

\subsection*{3. VAE class}
Write a class \texttt{VAE} that is a subclass of PyTorch \texttt{nn.module} that implements the a full VAE. To do this, the class should implement the following functions:
\subsubsection*{Constructor}
An encoder constructor \texttt{\_\_init\_\_(self, c1, c2, lat, k)}, where \texttt{c1} is the output channel size of the first encoder convolution layer, \texttt{c2} is the output channel size of the second encoder convolution layer, \texttt{lat} is the latent dimension size, and \texttt{k} is the kernel size. Do not forget \texttt{super(VAE, self).\_\_init\_\_()}. The constructor initialize an \texttt{Encoder} object and a \texttt{Decoder} object.

\subsubsection*{Reconstruction loss function}
A function \texttt{r\_loss(self, x, y)}, where \texttt{x} is a batch of autoencoder output images and  \texttt{y} is a batch of ground truth images. The function should calculate the loss between the output and ground truth with total sum binary crossentropy formula

\[-[x \odot \log y + (1 - x) \odot \log(1 - y)]\] 

\noindent
where $\odot$ is the element-wise multiplication operator.

\subsubsection*{KL divergence function}
A function \texttt{kl\_loss(self, mu, sigma)}, calculates the KL divergence given \texttt{mu} and \texttt{sigma} between two probability distributions. As discussed, the goal of this function is to force the latent space into a normal distribution. The KL divergence for a normal distribution in this case can be calculated as

\[\mu ^ 2 + \sigma ^ 2 - \log\sigma - \frac{1}{2}\]

\subsubsection*{Gaussian function}
A function \texttt{gaussian(self, mu, sigma)}, which performs the reparameterization trick on \texttt{mu} and \texttt{sigma}. This function should return the output of 

\[\mu + \sigma \odot \mathcal{N}\]

\noindent
where $\mathcal{N}$ is a normal distribution random tensor with shape equal to \texttt{sigma}, a mean of 0, and a standard deviation of 1.

\subsubsection*{Forward function}
A function \texttt{forward(self, x)}, where \texttt{x} is a batch of images. The function should apply the encoder object to \texttt{x} to obtain \texttt{mu} and \texttt{sigma}, then apply \texttt{gaussian} to \texttt{mu} and \texttt{sigma} to obtain \texttt{z}, and then apply the decoder to \texttt{z} to obtain \texttt{y}. Calculate \texttt{loss} by adding together \texttt{r\_loss(x, y)} and \texttt{kl\_loss(mu, sigma)} and store \texttt{loss} as an instance variable. Return \texttt{y}.

\subsubsection*{Backward function}
A function \texttt{backward(self)}, which initiates backpropagation. It should call the \texttt{backward} function for \texttt{loss} by calling \texttt{self.loss.backward()}.

\subsection*{2. Train VAE}
The VAE should be trained using the PyTorch \texttt{Adam} optimizer approximately as follows:

\begin{verbatim}
vae = VAE(c1, c2, lat, k)
adam = Adam(vae.parameters())

for e in range(num_epochs):
    loss = 0
    for x_batch, _ in training_data:
        adam.zero_grad()
        vae.forward(x_batch)

        loss += vae.loss
        vae.backward()
        adam.step()

    print(f"Training loss [{e + 1}/{num_epochs}]: {loss:0.4f}")
\end{verbatim}

\subsection*{3. Feature selection}
Apply the trained encoder \texttt{vae.encoder} and \texttt{gaussian} function to the test set images to obtain a list of embeddings. Select and store the indices of the two latent dimensions with the highest variance.

\subsection*{4. Verify normal distribution}
Slice the list of embeddings using the two indices. Plot both of these slices using Matplotlib \texttt{hist2d(slice1, slice2, bins=50)}. Verify that the distribution is centered on 0 and roughly resembles a normal distribution.

\subsection*{4. Perturb along one dimension}
Generate new images from the latent space. Create a list of 7 evenly spaced values from 0.05 to 0.95. Apply the SciPy \texttt{norm.ppf} function to this list to obtain numbers from the normal distribution. For each number \texttt{k}, create a vector of size \texttt{d} with all entries set to 0. Set the entry at one index to \texttt{k}. This index should be from one of the indices obtained earlier. Apply the trained decoder \texttt{vae.decoder} to these vectors and display the output images as a 1 by 7 grid. Verify that the images change consistently from one end to the other. As a bonus, do this with both previously obtained indices simultaneously to create a 7 by 7 grid.

\end{document}